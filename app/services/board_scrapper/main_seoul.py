from app.services.board_scrapper.base import BoardScraper
import requests
from bs4 import BeautifulSoup
import re

class MainBoardSeoulScraper(BoardScraper):

    def __init__(self):
    # ê¸°ë³¸ URLê³¼ íŒŒë¼ë¯¸í„°ë¥¼ í´ë˜ìŠ¤ ë‚´ë¶€ì— ì§€ì •
        self.base_url = "https://www.smu.ac.kr/kor/life/notice.do"
        self.params = {
            "srCampus": "smu",
            "mode": "list", 
            "articleLimit": 50, 
            "article.offset": 0
        }
        self.board_id = 2
        

    def scrape(self) -> dict:
        print("MainBoardSeoulScraper: ì‹œì‘")
        """ê²Œì‹œíŒ ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•˜ëŠ” ë©”ì„œë“œ"""
        # ì›¹í˜ì´ì§€ ìš”ì²­
        response = requests.get(self.base_url, params=self.params)
        response.raise_for_status()  # ìš”ì²­ ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ

        # HTML íŒŒì‹±
        soup = BeautifulSoup(response.text, "html.parser")

        # ê²Œì‹œë¬¼ ëª©ë¡ ì¶”ì¶œ
        posts = {}

        for li in soup.select(".board-thumb-wrap > li"):
            # ê³µì§€ê¸€ì¼ ê²½ìš° ë¬´ì‹œ 
            if li.select_one(".noti"):
                continue

            # ìº í¼ìŠ¤ ì •ë³´
            campus_tag = li.select_one(".cmp")
            if campus_tag:
                campus_class = campus_tag["class"]  # í´ë˜ìŠ¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
                if "sang" in campus_class:
                    # ìƒëª…ì¸ ê²½ìš°ëŠ” ì²˜ë¦¬í•˜ì§€ ì•Šê³  ê±´ë„ˆë›°ê¸°
                    continue  
                    campus = "ìƒëª…"
                elif "seoul" in campus_class:
                    campus = "ì„œìš¸"
                else:
                    campus = "N/A"
            else:
                campus = "N/A"

            # ğŸ“Œ ê²Œì‹œê¸€ ID
            article_id_tag = li.select_one(".board-thumb-content-number")
            article_id = article_id_tag.get_text(strip=True) if article_id_tag else "N/A"
            article_id = re.sub(r"No\.", "", article_id).strip()  # "No." ì œê±°

            # ğŸ”— ê²Œì‹œê¸€ URL
            article_link_tag = li.select(".board-thumb-content-title a")[1]  # ë‘ ë²ˆì§¸ <a> íƒœê·¸ë¥¼ ì„ íƒ
            article_url = self.base_url + article_link_tag["href"] if article_link_tag else "N/A"

            # ğŸ“ ì œëª©
            title_tag = li.select(".board-thumb-content-title a")[1]  # ë‘ ë²ˆì§¸ <a> íƒœê·¸ë¥¼ ì„ íƒ
            title = title_tag.text.strip() if title_tag else "N/A"

            # ğŸ“… ê²Œì‹œ ë‚ ì§œ
            date_tag = li.select_one(".board-thumb-content-date")
            date = date_tag.text.strip() if date_tag else "N/A"
            date = re.sub(r"ì‘ì„±ì¼", "", date).strip()

            # ğŸ· ì¹´í…Œê³ ë¦¬ (ì¼ë°˜, í•™ì‚¬ ë“±)
            category_tag = li.select_one(".cate")
            category = category_tag.text.strip("[]") if category_tag else "N/A"

            # ğŸ‘€ ì¡°íšŒìˆ˜
            views_tag = li.select_one(".board-thumb-content-views")
            views = views_tag.text.strip() if views_tag else "0"
            views = re.sub(r"ì¡°íšŒìˆ˜", "", views).strip()  # "ì¡°íšŒìˆ˜" ì œê±°

            # ğŸ“‚ ì²¨ë¶€íŒŒì¼ ì—¬ë¶€
            file_tag = li.select_one(".list-file a")
            has_attachment = True if file_tag else False  # ì²¨ë¶€íŒŒì¼ì´ ìˆìœ¼ë©´ True, ì—†ìœ¼ë©´ False

            # ğŸ—‚ í•´ì‹œ í…Œì´ë¸”ì— ì €ì¥
            posts[article_id] = {
                "id": article_id,
                "title": title,
                "date": date,
                "campus": campus,
                "post_type": category,
                "view_count": views,
                "url": article_url,
                "has_reference": has_attachment  
            }

        print(posts)
        print("MainBoardSeoulScraper: ì™„ë£Œ")



        return {"board_id" : self.board_id, "count": len(posts), "data" : posts}


# í…ŒìŠ¤íŠ¸ ì‹¤í–‰    
if __name__ == "__main__":
    scraper = MainBoardSeoulScraper()
    data = scraper.scrape()
    print(data)
